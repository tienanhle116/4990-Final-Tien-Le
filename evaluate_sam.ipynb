{"cells": [{"cell_type": "markdown", "metadata": {}, "source": ["# Evaluate SAM on Sample Images\n", "This notebook loads the Segment Anything Model (SAM), runs it on test images, and visualizes the masks."]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Install and import required packages\n", "import torch\n", "import numpy as np\n", "import matplotlib.pyplot as plt\n", "import cv2\n", "from segment_anything import SamPredictor, sam_model_registry\n", "from PIL import Image"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load the model\n", "sam = sam_model_registry[\"vit_b\"](checkpoint=\"sam_vit_b.pth\")\n", "predictor = SamPredictor(sam)\n", "predictor.model.eval();"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Load test image\n", "image_path = \"../data/coco_sample/sample1.jpg\"  # Update with actual path\n", "image = cv2.imread(image_path)\n", "image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n", "predictor.set_image(image_rgb)"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Provide a point prompt and get mask\n", "input_point = np.array([[300, 400]])  # Example coordinates\n", "input_label = np.array([1])\n", "masks, scores, logits = predictor.predict(\n", "    point_coords=input_point,\n", "    point_labels=input_label,\n", "    multimask_output=True\n", ")"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["# Visualize results\n", "for i, mask in enumerate(masks):\n", "    plt.figure()\n", "    plt.imshow(image_rgb)\n", "    plt.imshow(mask, alpha=0.5)\n", "    plt.title(f\"Mask {i+1} (Score: {scores[i]:.2f})\")\n", "    plt.axis('off')\n", "plt.show()"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"name": "python", "version": "3.9"}}, "nbformat": 4, "nbformat_minor": 5}